-------------- #This is the R Markdown Code Source file, open in RStudio if you wish to run the Individual Code Blocks and see the output for each block --------------

---
title: "HeartDPred_PreAnalysis"
author: "Tyler Boudreau"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{R}
# Required packages
library(caret)
library(ggcorrplot)
library(GGally)
library(randomForest)
library(xgboost)
library(Metrics)
library(rpart)
library(rpart.plot)
library(pROC)
library(ggplot2)
library(plotly)
```

```{R}
Clev_HeartD <- read.csv('C:\\Users\\Tyler\\Downloads\\Heart_disease_cleveland_new.csv') # File locatiom for Data
set.seed(3573)

```

```{R}
#plot correlation matrix to check for Multicollinearity 
ggcorr(Clev_HeartD, label = TRUE, digits = 3, label_size = 3)

# Plot shows possible Multicollinearity, for Slope and Oldpeak variables

# Could remove least important one to possibly improve model if desired
```

```{R}
set.seed(3573) # sets seed 
sample1 <- sample(c(TRUE,FALSE),nrow(Clev_HeartD),replace=TRUE, prob = c(0.70,0.30)) # 70 percent of data for train / supervised learning, 30 percent for test / unsupervised learning.

train <- Clev_HeartD[sample1, ]#Supervised learning Train partition
test <- Clev_HeartD[!sample1, ]#Unsupervised learning Test Partition

```

```{R}
# Basic Decision tree model
HeartDTree <- rpart(target~.,data = train)
rpart.plot(HeartDTree)
pred_dt <- predict(HeartDTree,test)
test_rocDt = roc(test$target ~pred_dt,plot = TRUE, print.auc = TRUE) # ROC curve for Decision tree model
```


```{R}
# Random Forest Model
HeartDForest <- randomForest(target~., data = train, importance = TRUE)

print(HeartDForest)
print(importance(HeartDForest,type=2))
```


```{R}
pred2 <- predict(HeartDForest,test)
print(mean((pred2-test$target)))^2

#Evaluate Reciver operator Curve ROC for model to assess accuracy for Random Forest model
test_roc = roc(test$target ~pred2,plot = TRUE, print.auc = TRUE)
```


```{R}
train_x = data.matrix(train[,-14]) # 14 is number of predictors
train_y = train[,14]
test_x = data.matrix(test[,-14])
test_y = data.matrix(test[,14])
#HeartDTest1 <- data.frame(age = c(63), sex = c(1), cp = c(0), trestbps = c(145), chol = c(233), fbs = c(1), restecg = c(2), thalach = (150), exang = c(0), oldpeak = (2.3), slope = c(2), ca= c(0), thal = c(2)) example values to test
#predict(HeartDForest, HeartDTest1)
xgb_train <- xgb.DMatrix(data = train_x, label = train_y)
xgb_test <- xgb.DMatrix(data = test_x, label = test_y)
watchlist = list(train=xgb_train, test=xgb_test)
#Observe and compare Train and test rmse and pick when test unsupervised learning error is lowest to avoid overfitting and to have best model accuracy
xgbmodel = xgb.train(data = xgb_train, max.depth = 3, watchlist=watchlist, nrounds = 20)
xgbfinal = xgboost(data = xgb_train, max.depth = 3, nround = 6, verbose = 0) #Final value for nrounds depends on your exact run, exaple for this is 6 rounds for lowest rmse
pred_y = predict(xgbfinal, xgb_test) # Make predictions with model 

mse(test_y,pred_y) # evaluate error of model

#Evaluate Reciver operator Curve ROC for model to assess accuracy for xgboost model
test_roc = roc(test_y~pred_y, plot = TRUE, print.auc = TRUE)

```


```{R} 
#Create importance Bar Graph
importance <- importance(HeartDForest) 
vImportance <- data.frame(Variables = row.names(importance),Importance =round(importance[,'IncNodePurity'], 0))

ggplotly(ggplot(vImportance, aes(x = reorder(Variables, Importance), 
y = Importance, fill=Importance))+geom_bar(stat='identity') + 
labs(title = 'Importance of HeartD predictors', x = 'Predictors', y = 'Importance') +
coord_flip())

#CP and ca are most important factors
```
